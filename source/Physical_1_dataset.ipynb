{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import numpy\n",
    "import plotly.express\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, balanced_accuracy_score, matthews_corrcoef, average_precision_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import xgboost\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"data/Physical dataset/phy_att_1.csv\", encoding=\"utf-16le\", delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_attaque= df['Label'].value_counts()\n",
    "print(nb_attaque)\n",
    "ratio = (nb_attaque.iloc[1]+nb_attaque.iloc[2])/(nb_attaque.iloc[0]+nb_attaque.iloc[1]+nb_attaque.iloc[2])\n",
    "print(ratio*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_catégorielles = df.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "# Extraction des noms des colonnes numériques\n",
    "colonnes_numériques = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print(\"Colonnes catégorielles :\")\n",
    "print(colonnes_catégorielles)\n",
    "\n",
    "print(\"\\nColonnes numériques :\")\n",
    "print(colonnes_numériques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_stats = df[colonnes_catégorielles].describe()\n",
    "print(cat_stats)\n",
    "print()\n",
    "valeur_catégorielles = {}\n",
    "for col in colonnes_catégorielles:\n",
    "    valeur_catégorielles[col] = df[col].unique()\n",
    "    print(\"%s: %s\" % (col, valeur_catégorielles[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract statistics for each numeric column\n",
    "numeric_stats = df[colonnes_numériques].describe()\n",
    "\n",
    "# Print the list of numeric columns\n",
    "print(\"Numeric Columns:\")\n",
    "print(colonnes_numériques)\n",
    "\n",
    "# Print statistics for each numeric column\n",
    "print(\"\\nStatistics for Numeric Columns:\")\n",
    "print(numeric_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratios = df.isna().mean()   \n",
    "print(nan_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_attack_categories  = df['Label'].unique()\n",
    "print(target_attack_categories)\n",
    "target_attack_categories = target_attack_categories[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(target_attack_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on récupère tous les labels 1\n",
    "MM = df[(df['Label_n'] == 1)]\n",
    "#on récupère toute les colonnes où il y a bien une attaque pour un label 1\n",
    "matching_rows = (MM['Label'].isin(target_attack_categories))\n",
    "# on vérifie que l'on a bien que la valeur True\n",
    "print(matching_rows.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on récupère tous les labels 0\n",
    "MM = df[(df['Label_n'] == 0)]\n",
    "#on récupère toute les colonnes où il y a bien une attaque pour un Label 0\n",
    "matching_rows =(MM['Label'].isin([\"normal\"]))\n",
    "# on vérifie que l'on a bien que la valeur True\n",
    "print(matching_rows.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame X you will use for cleaning.\n",
    "fraudulent_entries = df[df['Label_n'] == 1].sample(n=int(1000 * ratio) +1)\n",
    "\n",
    "# Sample non-fraudulent entries to match the ratio\n",
    "non_fraudulent_entries = df[df['Label_n'] == 0].sample(n=int(1000 * (1-ratio)))\n",
    "\n",
    "# Concatenate both sets to create df_reduced\n",
    "X = pandas.concat([fraudulent_entries, non_fraudulent_entries])\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame X you will use for cleaning.\n",
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the attack_cat labels in a DataFrame Y as a 1-D array\n",
    "Y = X['Label_n'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['Label', 'Time','Label_n'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract train and test data through train_test_split on X and Y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred_proba = clf.predict_proba(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix:', confusion_matrix(Y_test, Y_pred))\n",
    "print('Precision:', precision_score(Y_test, Y_pred))\n",
    "print('Recall:', recall_score(Y_test, Y_pred))\n",
    "print('Accuracy:', accuracy_score(Y_test, Y_pred))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(Y_test, Y_pred))\n",
    "print('Matthews Correlation Coefficient:', matthews_corrcoef(Y_test, Y_pred))\n",
    "print('AUPRC:', average_precision_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the XGBClassifier interface in sklearn\n",
    "# 1. Perform the same analysis\n",
    "# 2. Plot the relative importance of fields through plot_importance, using importance_type ‘cover’, ‘gain’, ‘weight’\n",
    "# 3. Show the classifier visually\n",
    "\n",
    "\n",
    "clf = xgboost.XGBClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "print('Confusion matrix:', confusion_matrix(Y_test, Y_pred))\n",
    "print('Precision:', precision_score(Y_test, Y_pred))\n",
    "print('Recall:', recall_score(Y_test, Y_pred))\n",
    "print('Accuracy:', accuracy_score(Y_test, Y_pred))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(Y_test, Y_pred))\n",
    "print('Matthews Correlation Coefficient:', matthews_corrcoef(Y_test, Y_pred))\n",
    "print('AUPRC:', average_precision_score(Y_test, Y_pred))\n",
    "\n",
    "fig = plotly.express.imshow(confusion_matrix(Y_test, Y_pred), title='Confusion matrix')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "Y_pred_proba = knn.predict_proba(X_test)\n",
    "\n",
    "print(\"Confusion matrix:\", confusion_matrix(Y_test, Y_pred))\n",
    "print(\"Precision:\", precision_score(Y_test, Y_pred))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(Y_test, Y_pred))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(Y_test, Y_pred))\n",
    "print(\"AUPRC:\", average_precision_score(Y_test, Y_pred))\n",
    "\n",
    "fig = plotly.express.imshow(confusion_matrix(Y_test, Y_pred), title=\"Confusion matrix\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = pandas.read_csv(\"data/Physical dataset/phy_att_4.csv\", encoding=\"utf-8\", delimiter=',')\n",
    "Y = F['Label_n'].copy()\n",
    "F.drop(['Label', 'Time','Label_n'], axis=1, inplace=True)\n",
    "\n",
    "Y_pred = clf.predict(F)\n",
    "Y_pred_proba = clf.predict_proba(F)\n",
    "\n",
    "print('Confusion matrix:', confusion_matrix(Y, Y_pred))\n",
    "print('Precision:', precision_score(Y, Y_pred))\n",
    "print('Recall:', recall_score(Y, Y_pred))\n",
    "print('Accuracy:', accuracy_score(Y, Y_pred))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(Y, Y_pred))\n",
    "print('Matthews Correlation Coefficient:', matthews_corrcoef(Y, Y_pred))\n",
    "print('AUPRC:', average_precision_score(Y, Y_pred))\n",
    "\n",
    "fig = plotly.express.imshow(confusion_matrix(Y, Y_pred), title='Confusion matrix')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les résultats ne sont pas \"bon\" (on a pas 0.97 que l'on aurait si on entraine sur tout (ce qui n'est pas beacoup plus long))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
