{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import numpy\n",
    "import plotly.express\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, balanced_accuracy_score, matthews_corrcoef, average_precision_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import xgboost\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Créez un DataFrame vide\n",
    "df = []\n",
    "\n",
    "# Chemin vers le répertoire contenant vos fichiers CSV\n",
    "csv_files = glob.glob('data/Physical dataset/*.csv')\n",
    "print(csv_files)\n",
    "# Parcourez la liste de fichiers CSV et ajoutez-les au DataFrame\n",
    "for csv_file in csv_files:\n",
    "    delimiter = '\\t'\n",
    "    encoding=\"utf-16le\"\n",
    "    if csv_file.endswith(\"4.csv\"):\n",
    "        delimiter = ','\n",
    "        encoding = \"utf-8\"\n",
    "    df_temp = pandas.read_csv(csv_file, encoding=encoding, delimiter=delimiter)\n",
    "    df.append(df_temp)\n",
    "\n",
    "df  = pandas.concat(df, ignore_index=True)\n",
    "# Maintenant, df contient l'ensemble des données de tous les fichiers CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Remplacer les valeurs non nulles dans Label_n par celles de Lable_n\n",
    "df['Label_n'] = df['Label_n'].combine_first(df['Lable_n'])\n",
    "\n",
    "# Supprimer la colonne Lable_n\n",
    "df.drop('Lable_n', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_attaque= df['Label'].value_counts()\n",
    "print(nb_attaque)\n",
    "ratio = (nb_attaque.iloc[1] + nb_attaque.iloc[2]+ nb_attaque.iloc[3] + nb_attaque.iloc[5])/(nb_attaque.iloc[0]+nb_attaque.iloc[1]+nb_attaque.iloc[2]+ nb_attaque.iloc[3] + nb_attaque.iloc[4] +nb_attaque.iloc[5])\n",
    "print(ratio*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on test sur des partie du dataframe pour voir le nombre minimal de data à prendre pour avoir un bon F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create reduced datasets\n",
    "train_sizes = [100, 500,1000,5000,10000]\n",
    "reduced_datasets = {}\n",
    "# Define the sizes of X_train you want to experiment with\n",
    "\n",
    "# Initialize lists to store results\n",
    "\n",
    "recall_scores = []\n",
    "accuracy_scores = []\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "#on drop Label, Time et Label_n pour pouvoir faire l'apprentissage\n",
    "#Label_n met aussi les erreur physique comme attaque, or ce ne sont pas des attaques. C'est pourquoi on utilise pas cette colonne et on créer nous même une colonne.\n",
    "\n",
    "\n",
    "for size in train_sizes:\n",
    "\n",
    "    fraudulent_entries = df[df['Label_n'] == 1].sample(n=int(size * ratio) +1)\n",
    "    non_fraudulent_entries = df[df['Label_n'] == 0].sample(n=int(size * (1-ratio)))\n",
    "\n",
    "    # Concatenate both sets to create df_reduced\n",
    "    df_reduced = pandas.concat([fraudulent_entries, non_fraudulent_entries])\n",
    "\n",
    "    # Store the reduced dataset\n",
    "    reduced_datasets[size] = df_reduced\n",
    "    Y_red=df_reduced['Label_n'].copy()\n",
    "    X_red=df_reduced.drop(['Label_n', 'Time','Label'], axis=1)\n",
    "    # Optionally, split the reduced dataset into training and test sets\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X_red, Y_red, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Create an RF classifier\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_pred = clf.predict(X_test)\n",
    "    Y_pred_proba = clf.predict_proba(X_test)\n",
    "    # Evaluate the RF classifier\n",
    "   \n",
    "    recall_scores.append(recall_score(Y_test, Y_pred))\n",
    "    accuracy_scores.append(accuracy_score(Y_test, Y_pred))\n",
    "\n",
    "# Plot the results\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "plt.plot(train_sizes, recall_scores, label='Recall')\n",
    "plt.plot(train_sizes, accuracy_scores, label='Accuracy')\n",
    "\n",
    "plt.title('Random forest Classifier Performance for Different Training Set Sizes')\n",
    "plt.xlabel('Training Set Size')\n",
    "plt.ylabel('Score')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import plotly.express as px\n",
    "\n",
    "# Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "Y_pred_rf = rf_classifier.predict(X_test)\n",
    "# Evaluate the Random Forest classifier\n",
    "print('Random Forest Classifier Metrics:')\n",
    "print('Confusion matrix:', confusion_matrix(Y_test, Y_pred_rf))\n",
    "print('Precision:', precision_score(Y_test, Y_pred_rf))\n",
    "print('Recall:', recall_score(Y_test, Y_pred_rf))\n",
    "print('Accuracy:', accuracy_score(Y_test, Y_pred_rf))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(Y_test, Y_pred_rf))\n",
    "print('Matthews Correlation Coefficient:', matthews_corrcoef(Y_test, Y_pred_rf))\n",
    "print('AUPRC:', average_precision_score(Y_test, Y_pred_rf))\n",
    "\n",
    "# Visualize the confusion matrix\n",
    "fig_rf = px.imshow(confusion_matrix(Y_test, Y_pred_rf), title='Random Forest Confusion matrix')\n",
    "fig_rf.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
