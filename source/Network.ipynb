{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import numpy\n",
    "import plotly.express\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, balanced_accuracy_score, matthews_corrcoef, average_precision_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import xgboost\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pandas.read_csv(\"data/Network datatset/csv/attack_1.csv\", encoding=\"us-ascii\", delimiter=',', skipinitialspace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_attaque= df['label'].value_counts()\n",
    "print(nb_attaque)\n",
    "ratio = (nb_attaque.iloc[1]+nb_attaque.iloc[2]+nb_attaque.iloc[3])/(nb_attaque.iloc[0]+nb_attaque.iloc[1]+nb_attaque.iloc[2]+nb_attaque.iloc[3])\n",
    "print(ratio*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nb_attaque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['modbus_fn'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_catégorielles = df.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "colonnes_numériques = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print(\"Colonnes catégorielles :\")\n",
    "print(colonnes_catégorielles)\n",
    "\n",
    "print(\"\\nColonnes numériques :\")\n",
    "print(colonnes_numériques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_stats = df[colonnes_catégorielles].describe()\n",
    "print(cat_stats)\n",
    "print()\n",
    "valeur_catégorielles = {}\n",
    "for col in colonnes_catégorielles:\n",
    "    valeur_catégorielles[col] = df[col].unique()\n",
    "    print(\"%s: %s\" % (col, valeur_catégorielles[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_stats = df[colonnes_numériques].describe()\n",
    "\n",
    "print(\"Numeric Columns:\")\n",
    "print(colonnes_numériques)\n",
    "\n",
    "print(\"\\nStatistics for Numeric Columns:\")\n",
    "print(numeric_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "for v in ('Time', 'mac_s', 'mac_d', 'ip_s', 'ip_d', 'proto', 'modbus_fn', 'modbus_response', 'label'):\n",
    "    print(\"Number of unique values for {}: {}\".format(v, df[v].nunique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratios = df.isna().mean()   \n",
    "print(nan_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "df_filtre = df[df['modbus_fn'].isna()]\n",
    "\n",
    "nombre_de_1 = df_filtre['label_n'].sum()\n",
    "print(\"Le nombre de 1 dans la colonne 'label' pour les valeurs manquantes dans 'modbus_fn' est :\", nombre_de_1)\n",
    "print(df_filtre.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_attack_categories  = df['label'].unique()\n",
    "target_attack_categories = target_attack_categories[1:4]\n",
    "print(target_attack_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on récupère tous les labels 1\n",
    "MM = df[(df['label_n'] == 1)]\n",
    "#on récupère toute les colonnes où il y a bien une attaque pour un label 1\n",
    "matching_rows = (MM['label'].isin(target_attack_categories))\n",
    "# on vérifie que l'on a bien que la valeur True\n",
    "print(matching_rows.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on récupère tous les labels 0\n",
    "MM = df[(df['label_n'] == 0)]\n",
    "\n",
    "#on récupère toute les colonnes où il y a bien une attaque pour un Label 0\n",
    "matching_rows =(MM['label'].isin([\"normal\"]))\n",
    "# on vérifie que l'on a bien que la valeur True\n",
    "print(matching_rows.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_fraud = df['label_n'].value_counts()\n",
    "print(nb_fraud)\n",
    "ratio = nb_fraud[1]/(nb_fraud[0]+nb_fraud[1])\n",
    "print(ratio*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame X you will use for cleaning.\n",
    "fraudulent_entries = df[df['label_n'] == 1].sample(n=int(10000 * ratio) +1)\n",
    "\n",
    "# Sample non-fraudulent entries to match the ratio\n",
    "non_fraudulent_entries = df[df['label_n'] == 0].sample(n=int(10000 * (1-ratio)))\n",
    "\n",
    "# Concatenate both sets to create df_reduced\n",
    "X = pandas.concat([fraudulent_entries, non_fraudulent_entries])\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Remplacez les valeurs '[int]' par 'int' et transformez la colonne en numérique\n",
    "X['modbus_response'] = X['modbus_response'].str.replace(r'\\[(\\d+)\\]', r'\\1', regex=True)\n",
    "X['modbus_response'] = pandas.to_numeric(X['modbus_response'], errors='coerce')\n",
    "X['modbus_response'] = X['modbus_response'].fillna(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratios = X.isna().mean()   \n",
    "print(nan_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_catégorielles = X.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "# Extraction des noms des colonnes numériques\n",
    "colonnes_numériques = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print(\"Colonnes catégorielles :\")\n",
    "print(colonnes_catégorielles)\n",
    "\n",
    "print(\"\\nColonnes numériques :\")\n",
    "print(colonnes_numériques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the attack_cat labels in a DataFrame Y as a 1-D array\n",
    "Y = X['label_n'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['label', 'Time','label_n'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pandas.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract train and test data through train_test_split on X and Y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred_proba = clf.predict_proba(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix:', confusion_matrix(Y_test, Y_pred))\n",
    "print('Precision:', precision_score(Y_test, Y_pred))\n",
    "print('Recall:', recall_score(Y_test, Y_pred))\n",
    "print('Accuracy:', accuracy_score(Y_test, Y_pred))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(Y_test, Y_pred))\n",
    "print('Matthews Correlation Coefficient:', matthews_corrcoef(Y_test, Y_pred))\n",
    "print('AUPRC:', average_precision_score(Y_test, Y_pred))\n",
    "fig = plotly.express.imshow(confusion_matrix(Y_test, Y_pred), title=\"Confusion matrix\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the XGBClassifier interface in sklearn\n",
    "# 1. Perform the same analysis\n",
    "# 2. Plot the relative importance of fields through plot_importance, using importance_type ‘cover’, ‘gain’, ‘weight’\n",
    "# 3. Show the classifier visually\n",
    "\n",
    "'''\n",
    "clf = xgboost.XGBClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "print('Confusion matrix:', confusion_matrix(Y_test, Y_pred))\n",
    "print('Precision:', precision_score(Y_test, Y_pred))\n",
    "print('Recall:', recall_score(Y_test, Y_pred))\n",
    "print('Accuracy:', accuracy_score(Y_test, Y_pred))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(Y_test, Y_pred))\n",
    "print('Matthews Correlation Coefficient:', matthews_corrcoef(Y_test, Y_pred))\n",
    "print('AUPRC:', average_precision_score(Y_test, Y_pred))\n",
    "\n",
    "fig = plotly.express.imshow(confusion_matrix(Y_test, Y_pred), title='Confusion matrix')\n",
    "fig.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "# Liste des valeurs de k à tester\n",
    "k_values = range(1, 10)\n",
    "\n",
    "# Liste pour stocker les scores de précision\n",
    "accuracy_scores = []\n",
    "recall_scores = []\n",
    "# Test de chaque valeur de k\n",
    "for k in k_values:\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, y_pred)\n",
    "    recall = recall_score(Y_test, y_pred)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    recall_scores.append(recall)\n",
    "\n",
    "# Création d'un DataFrame pour utiliser plotly.express\n",
    "data = {'k': k_values, 'Précision': accuracy_scores, 'Rappel': recall_scores}\n",
    "D = pd.DataFrame(data)\n",
    "\n",
    "# Tracer la courbe du critère du coude avec plotly.express\n",
    "fig = plotly.express.line(D, x='k', y=['Précision', 'Rappel'], markers=True,\n",
    "              title='Critère du Coude pour le KNN')\n",
    "fig.update_layout(xaxis_title='Nombre de voisins (k)', yaxis_title='Score')\n",
    "fig.show()\n",
    "\n",
    "#Best precision for k=1\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "Y_pred_proba = knn.predict_proba(X_test)\n",
    "\n",
    "print(\"Confusion matrix:\", confusion_matrix(Y_test, Y_pred))\n",
    "print(\"Precision:\", precision_score(Y_test, Y_pred))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(Y_test, Y_pred))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(Y_test, Y_pred))\n",
    "print(\"AUPRC:\", average_precision_score(Y_test, Y_pred))\n",
    "\n",
    "fig = plotly.express.imshow(confusion_matrix(Y_test, Y_pred), title=\"Confusion matrix\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
