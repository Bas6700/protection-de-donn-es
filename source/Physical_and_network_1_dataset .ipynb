{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import numpy\n",
    "import plotly.express\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, balanced_accuracy_score, matthews_corrcoef, average_precision_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import xgboost\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import gc\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pandas.read_csv(\"data/Physical dataset/phy_att_1.csv\", encoding=\"utf-16le\", delimiter='\\t')\n",
    "df2 = pandas.read_csv(\"data/Network datatset/csv/attack_1.csv\", encoding=\"us-ascii\", delimiter=',', skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['Time'] = pandas.to_datetime(df1['Time']).dt.round('S')\n",
    "df2['Time'] = pandas.to_datetime(df2['Time'],format='ISO8601',yearfirst=True).dt.round('S')\n",
    "df1['Time'] = df1['Time'].dt.strftime('%Y-%d-%m %H:%M:%S')\n",
    "df2['Time'] = df2['Time'].dt.strftime('%Y-%m-%d %H:%M:%S')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1.drop(['Label','Label_n'], axis=1, inplace=True)\n",
    "df2.drop(['label','label_n'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pandas.merge(df2,df1, how='outer',on='Time', validate=\"m:1\")\n",
    "\n",
    "\n",
    "del df1 \n",
    "del df2\n",
    "\n",
    "gc.collect()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_attaque= df['Label'].value_counts()\n",
    "print(nb_attaque)\n",
    "ratio = (nb_attaque.iloc[1]+nb_attaque.iloc[2])/(nb_attaque.iloc[0]+nb_attaque.iloc[1]+nb_attaque.iloc[2])\n",
    "print(ratio*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_catégorielles = df.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "# Extraction des noms des colonnes numériques\n",
    "colonnes_numériques = df.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print(\"Colonnes catégorielles :\")\n",
    "print(colonnes_catégorielles)\n",
    "\n",
    "print(\"\\nColonnes numériques :\")\n",
    "print(colonnes_numériques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_stats = df[colonnes_catégorielles].describe()\n",
    "print(cat_stats)\n",
    "print()\n",
    "valeur_catégorielles = {}\n",
    "for col in colonnes_catégorielles:\n",
    "    valeur_catégorielles[col] = df[col].unique()\n",
    "    print(\"%s: %s\" % (col, valeur_catégorielles[col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract statistics for each numeric column\n",
    "numeric_stats = df[colonnes_numériques].describe()\n",
    "\n",
    "# Print the list of numeric columns\n",
    "print(\"Numeric Columns:\")\n",
    "print(colonnes_numériques)\n",
    "\n",
    "# Print statistics for each numeric column\n",
    "print(\"\\nStatistics for Numeric Columns:\")\n",
    "print(numeric_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratios = df.isna().mean()   \n",
    "print(nan_ratios)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_attack_categories  = df['Label'].unique()\n",
    "target_attack_categories = target_attack_categories[1:4]\n",
    "print(target_attack_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on récupère tous les labels 1\n",
    "MM = df[(df['Label_n'] == 1)]\n",
    "#on récupère toute les colonnes où il y a bien une attaque pour un label 1\n",
    "matching_rows = (MM['Label'].isin(target_attack_categories))\n",
    "# on vérifie que l'on a bien que la valeur True\n",
    "print(matching_rows.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on récupère tous les labels 0\n",
    "MM = df[(df['Label_n'] == 0)]\n",
    "#on récupère toute les colonnes où il y a bien une attaque pour un Label 0\n",
    "matching_rows =(MM['Label'].isin([\"normal\"]))\n",
    "# on vérifie que l'on a bien que la valeur True\n",
    "print(matching_rows.all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraudulent_entries = df[df['Label_n'] == 1].sample(n=int(100000 * ratio) +1)\n",
    "\n",
    "# Sample non-fraudulent entries to match the ratio\n",
    "non_fraudulent_entries = df[df['Label_n'] == 0].sample(n=int(100000 * (1-ratio)))\n",
    "\n",
    "# Concatenate both sets to create df_reduced\n",
    "X = pandas.concat([fraudulent_entries, non_fraudulent_entries])\n",
    "print(X.shape)\n",
    "\n",
    "del df\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Créez un DataFrame exemple\n",
    "\n",
    "# Remplacez les valeurs '[int]' par 'int' et transformez la colonne en numérique\n",
    "X['modbus_response'] = X['modbus_response'].str.replace(r'\\[(\\d+)\\]', r'\\1', regex=True)\n",
    "X['modbus_response'] = pandas.to_numeric(X['modbus_response'], errors='coerce')\n",
    "X['modbus_response'] = X['modbus_response'].fillna(-1)\n",
    "# La colonne est maintenant de type numérique avec des valeurs numériques\n",
    "print(X['modbus_response'].unique())\n",
    "#X = X.fillna(-2)\n",
    "X = X.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_ratios = X.isna().mean()   \n",
    "print(nan_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the attack_cat labels in a DataFrame Y as a 1-D array\n",
    "Y = X['Label_n'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop(['Time','Label','Label_n'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pandas.get_dummies(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colonnes_catégorielles = X.select_dtypes(include=['category', 'object']).columns.tolist()\n",
    "\n",
    "# Extraction des noms des colonnes numériques\n",
    "colonnes_numériques = X.select_dtypes(include=['number']).columns.tolist()\n",
    "\n",
    "print(\"Colonnes catégorielles :\")\n",
    "print(colonnes_catégorielles)\n",
    "\n",
    "print(\"\\nColonnes numériques :\")\n",
    "print(colonnes_numériques)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract train and test data through train_test_split on X and Y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred_proba = clf.predict_proba(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Confusion matrix:', confusion_matrix(Y_test, Y_pred))\n",
    "print('Precision:', precision_score(Y_test, Y_pred))\n",
    "print('Recall:', recall_score(Y_test, Y_pred))\n",
    "print('Accuracy:', accuracy_score(Y_test, Y_pred))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(Y_test, Y_pred))\n",
    "print('Matthews Correlation Coefficient:', matthews_corrcoef(Y_test, Y_pred))\n",
    "print('AUPRC:', average_precision_score(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the XGBClassifier interface in sklearn\n",
    "# 1. Perform the same analysis\n",
    "# 2. Plot the relative importance of fields through plot_importance, using importance_type ‘cover’, ‘gain’, ‘weight’\n",
    "# 3. Show the classifier visually\n",
    "\n",
    "\n",
    "clf = xgboost.XGBClassifier()\n",
    "clf.fit(X_train, Y_train)\n",
    "Y_pred = clf.predict(X_test)\n",
    "Y_pred_proba = clf.predict_proba(X_test)\n",
    "\n",
    "print('Confusion matrix:', confusion_matrix(Y_test, Y_pred))\n",
    "print('Precision:', precision_score(Y_test, Y_pred))\n",
    "print('Recall:', recall_score(Y_test, Y_pred))\n",
    "print('Accuracy:', accuracy_score(Y_test, Y_pred))\n",
    "print('Balanced accuracy:', balanced_accuracy_score(Y_test, Y_pred))\n",
    "print('Matthews Correlation Coefficient:', matthews_corrcoef(Y_test, Y_pred))\n",
    "print('AUPRC:', average_precision_score(Y_test, Y_pred))\n",
    "\n",
    "fig = plotly.express.imshow(confusion_matrix(Y_test, Y_pred), title='Confusion matrix')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train, Y_train)\n",
    "Y_pred = knn.predict(X_test)\n",
    "Y_pred_proba = knn.predict_proba(X_test)\n",
    "\n",
    "print(\"Confusion matrix:\", confusion_matrix(Y_test, Y_pred))\n",
    "print(\"Precision:\", precision_score(Y_test, Y_pred))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(Y_test, Y_pred))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(Y_test, Y_pred))\n",
    "print(\"AUPRC:\", average_precision_score(Y_test, Y_pred))\n",
    "\n",
    "fig = plotly.express.imshow(confusion_matrix(Y_test, Y_pred), title=\"Confusion matrix\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
