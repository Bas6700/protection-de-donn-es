{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import os\n",
    "import numpy\n",
    "import plotly.express\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, accuracy_score, balanced_accuracy_score, matthews_corrcoef, average_precision_score\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = pandas.read_csv(\"data/Physical dataset/phy_att_3.csv\", encoding=\"utf-16le\", delimiter='\\t')\n",
    "df = pandas.read_csv(\"data/Physical dataset/phy_att_4.csv\", encoding=\"utf-8\", delimiter=',')\n",
    "\n",
    "#erreur orthographe pour attack 2\n",
    "LABLE=0\n",
    "\n",
    "mystring='Label_n'\n",
    "if LABLE:\n",
    "    mystring='Lable_n'\n",
    "\n",
    "# downsampling\n",
    "DOWN=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#downsampling\n",
    "X_ancien=X.copy()\n",
    "if DOWN:\n",
    "    df_class_0 = X[X[mystring] == 0]\n",
    "    df_class_1 = X[X[mystring] == 1]\n",
    "    min_rows = min(df_class_0.shape[0], df_class_1.shape[0])\n",
    "\n",
    "    df_class_0_sampled = df_class_0.sample(n=min_rows, random_state=42)\n",
    "    df_balanced = pandas.concat([df_class_0_sampled, df_class_1], ignore_index=True)\n",
    "\n",
    "    # Mélangez les lignes pour mélanger les deux classes\n",
    "    df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "    print(df_balanced.shape)\n",
    "    X=df_balanced\n",
    "    \n",
    "\n",
    "print(\"nombre de fraude et non-fraude\\n\",X[mystring].value_counts() )\n",
    "prc=100*df[mystring].value_counts()[1]/(X[mystring].value_counts()[1]+X[mystring].value_counts()[0])\n",
    "print(\"pourcentage de fraude:\",prc )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"nombre de fraude et non-fraude\\n\",X[mystring].value_counts() )\n",
    "prc=100*df[mystring].value_counts()[1]/(X[mystring].value_counts()[1]+X[mystring].value_counts()[0])\n",
    "print(\"pourcentage de fraude:\",prc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "df_reduced = X.groupby('Label').apply(lambda x: x.sample(frac=10000/X.shape[0]))\n",
    "\n",
    "print(\"nombre de fraude et non-fraude df_reduced:\\n\",df_reduced['Label'].value_counts() )\n",
    "prc=100*X['Label'].value_counts()[1]/(df_reduced['Label'].value_counts()[1]+X['Label'].value_counts()[0])\n",
    "print(\"pourcentage de fraude:\",prc )\n",
    "X=df_reduced\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the attack_cat labels in a DataFrame Y as a 1-D array\n",
    "Y = X[mystring].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#on drop Label, Time et Label_n pour pouvoir faire l'apprentissage\n",
    "#Label_n met aussi les erreur physique comme attaque, or ce ne sont pas des attaques. C'est pourquoi on utilise pas cette colonne et on créer nous même une colonne.\n",
    "X.drop(['Label', 'Time',mystring], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract train and test data through train_test_split on X and Y\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importez les bibliothèques nécessaires\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Créez le modèle SVM\n",
    "svm_model = SVC(kernel='rbf')  # Vous pouvez choisir différents noyaux comme 'linear', 'poly', 'rbf', etc.\n",
    "\n",
    "# Entraînez le modèle sur l'ensemble d'entraînement\n",
    "svm_model.fit(X_train, Y_train)\n",
    "\n",
    "# Faites des prédictions sur l'ensemble de test\n",
    "Y_pred = svm_model.predict(X_test)\n",
    "\n",
    "\n",
    "print(\"Confusion matrix:\", confusion_matrix(Y_test, Y_pred))\n",
    "print(\"Precision:\", precision_score(Y_test, Y_pred))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(Y_test, Y_pred))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(Y_test, Y_pred))\n",
    "print(\"AUPRC:\", average_precision_score(Y_test, Y_pred))\n",
    "\n",
    "fig = plotly.express.imshow(confusion_matrix(Y_test, Y_pred), title=\"Confusion matrix\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sur l'ensemble des données\n",
    "X_test=X_ancien\n",
    "Y_test = X_test[mystring].copy()\n",
    "X_test.drop(['Label', 'Time',mystring], axis=1, inplace=True)\n",
    " \n",
    " \n",
    "# Faites des prédictions sur l'ensemble de test\n",
    "Y_pred = svm_model.predict(X_test)\n",
    "\n",
    "\n",
    "\n",
    "print(\"Confusion matrix:\", confusion_matrix(Y_test, Y_pred))\n",
    "print(\"Precision:\", precision_score(Y_test, Y_pred))\n",
    "print(\"Recall:\", recall_score(Y_test, Y_pred))\n",
    "print(\"Accuracy:\", accuracy_score(Y_test, Y_pred))\n",
    "print(\"Balanced accuracy:\", balanced_accuracy_score(Y_test, Y_pred))\n",
    "print(\"Matthews Correlation Coefficient:\", matthews_corrcoef(Y_test, Y_pred))\n",
    "print(\"AUPRC:\", average_precision_score(Y_test, Y_pred))\n",
    "\n",
    "fig = plotly.express.imshow(confusion_matrix(Y_test, Y_pred), title=\"Confusion matrix\")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ff",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
